-
  name: Adaptive workload-management system using a portable EEG headset (Ongoing)
  location: UCSD
  advisor: Prof. Xinyu Zhang
  description: >
    We built a closed-loop system that aims to mitigate the user's cognitive workload level when performing daily tasks. 
    We measure the user's workload with EEG signal collected from Muse (a commercial EEG headset). Our workload classification model is trained with N-back tasks, and classification accuracy is 0.98. 
    With our system and a simple mitigation strategy, the user's performance on a series of N-back tasks can be improved by 16% (in terms of reaction time).
  image: /img/eeg.jpg
- 
  name: Gazescape (Ongoing)
  location: UCSD
  advisor: Prof. Nadir Weibel
  description: >
    Eye contact plays an important role in a successful and effective group discussion. However, as all classes are moved online during the pandemic, students use video conferencing softwares, such as Zoom, for remote discussion, 
    which lacks this important visual cue for communication. We propose Gazescape, a video communication system that enables eye-contact within the group to facilitate turn-taking process and communication efficiency. 
  image: /img/gazescape.jpg
-
  name: ARTEMIS (Augmented Reality Technology-Enabled reMote Integrated Surgery)
  location: UCSD
  advisor: Prof. Nadir Weibel
  description: >
    ARTEMIS is a collaborative system for surgical telementoring. The surgical ﬁeld is recreated for a remote expert in VR, and the remote expert annotations and avatar are displayed into the novice’s ﬁeld of view in real-time using AR. 
  image: /img/artemis.png
-
  name: GrandpARents
  location: UCSD
  advisor: Prof. Nadir Weibel (course project for CSE218 Fall 2019)
  description: >
    GrandpARents is a system deployed on HoloLens that helps elderly people with visual and/or hearing impairments to cope with their daily tasks.
    There are two main features in our system. The first one is real-time subtitle for one-on-one conversations. The subtitle will be automatically generated in front of the user when someone is talking;
    the second feature is Zoom, which allows the user to magnify an area of interest by simply taking a picture and resize it with gestures.
  image: /img/gp.jpg
  url: https://github.com/WeibelLab-Teaching/CSE218_Fa19_ARengers
-
  name: ThumbTrak
  location: Cornell University
  advisor: Prof. Cheng Zhang
  description: >
    ThumbTrak is a continuous one-handed thumb-on-fingers input technology.
    It allows the user to use the thumb to continuously input on fingers by tracking the position of the thumb using wearable motion sensing. It consists of a thumb-ring and a wristband.
    With ThumbTrak, the user is able to input on applications in one-hand, which demands continuously input capability, such as drawing and text entry applications.
  image: /img/proj1.jpg
  url: /pdfs/Intro_ThumbTrak.pdf
-
  name: On-Shelf Product Image Generation for Product Classification using GAN
  location: Shanghai Jiao Tong University & Clobotics Co.,Ltd
  advisor: Dr. Cong Yang, Prof. Weiyao Lin
  description: >
    We collected 50k+ real product (beverage) images with a self-built turntable, and cameras from 5 different angles.
    Then we use the images from our dataset and real on-shelf product images from our database to train a Cycle-GAN model.
    The model can generate 'fake' on-shelf product images which can be further used to train our product classification models, aiming at reducing the cost of manual data annotation.
  image: /img/gan_stage_res.png
-
  name: Approximate Random Dropout for DNN training acceleration in GPGPU
  location: Shanghai Jiao Tong University
  advisor: Prof. Li Jiang
  description: >
    The training phases of DNN consumes enormous processing time and energy, and conventional compression techniques can hardly be used in the training phase.
    We propose the Approximate Random Dropout to eliminate the unnecessary computation and data access. To compensate the performance loss we develop a SGD-based Search Algorithm to produce the distribution of dropout patterns.
  image: /img/proj2.png
  url: https://ieeexplore.ieee.org/abstract/document/8715135
# -
#   name: Virtual Dressing System
#   location: Shanghai Jiao Tong University
#   advisor: Prof. Weiyao Lin
#   description: >
#     This system is based on a RGBD camera (Kinect V2) and OpenPose.
#     We use Kinect SDK to retrieve 3D human pose and refine the 3D skeleton with 2D pose estimation obtained by OpenPose, and reproject the refined 2D skeleton back to 3D space using depth information.
#     This system can let user select clothes and try them on. The size of the clothes can be changed automatically according to the user's body shape.
#   image: /img/proj3.png
  # url: http://google.com
# -
#   name: 'RGBD-based Single Person 3D Pose Estimation (On Going)'
#   location: Shanghai Jiao Tong University
#   advisor: Weiyao Lin
#   description: >
#     This work is to estimate 3D human pose directly from RGB and depth images obtained by Kinect V2.
#     We first utilize a state-of-the-art 2D pose estimator to get 2D keypoints heatmaps and tile them along z-dimention. At the same time we voxelize the depth image.
#     Then the two features are combined together and fed into a Encoder-Decoder network to produce the 3D keypoints.
#   image: /img/proj4.png
  # url: http://google.com
# -
#   name: RNN-based Driver's Cognitive Workload Analysis
#   location: Shanghai Jiao Tong University
#   advisor: Na Ruan
#   description: >
#     This work is to estimate driver's cognitive workload while driving.
#     We use physiological data and driver's self-ratings while driving to generate ground truth and build a RNN-based realtime estimation system using only vehicle data such as acceleration and speed.
#
#   image: /img/proj5.png
#   # url: http://google.com
